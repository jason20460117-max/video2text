import streamlit as st
import time
import re
import os
import glob
from openai import OpenAI

# å°è¯•å¯¼å…¥æ–°åŠŸèƒ½åº“
try:
    import yt_dlp
    import whisper
    import torch
    import zhconv
except ImportError:
    st.error("âš ï¸ æ£€æµ‹åˆ°ç¼ºå°‘å¿…è¦åº“ï¼è¯·è¿è¡Œ: pip install yt-dlp openai-whisper torch zhconv")
    st.stop()

# ==========================================
# 1. é¡µé¢åŸºç¡€é…ç½®
# ==========================================
st.set_page_config(
    page_title="DeepFlow v8.3 (UI Fix)",
    page_icon="ğŸŒŠ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==========================================
# 2. å¼ºåˆ¶ç™½åº•é»‘å­— CSS + è¿›åº¦å—æ ·å¼
# ==========================================
st.markdown("""
<style>
    /* å…¨å±€ç™½åº•é»‘å­—ï¼Œå¹¶å¢åŠ è¡Œé«˜é˜²æ­¢ Emoji è¢«åˆ‡æ–­ */
    .stApp {background-color: #FFFFFF !important; color: #000000 !important;}
    section[data-testid="stSidebar"] {background-color: #F8F9FA !important; border-right: 1px solid #E9ECEF !important;}
    h1, h2, h3, h4, h5, h6, p, span, label, div {
        color: #212529 !important; 
        line-height: 1.6 !important; /* å…³é”®ä¿®å¤ï¼šå¢åŠ è¡Œé«˜ */
    }
    
    /* è¾“å…¥æ¡† */
    .stTextInput input, .stTextArea textarea {
        background-color: #FFFFFF !important; color: #000000 !important; border: 1px solid #CED4DA !important;
    }
    
    /* è¿›åº¦å—æ ·å¼ (Chunk Boxes) */
    .chunk-container {
        display: flex;
        flex-wrap: wrap;
        gap: 8px;
        margin-bottom: 15px;
        padding: 10px;
        background-color: #f8f9fa;
        border-radius: 8px;
        border: 1px solid #dee2e6;
    }
    .chunk-box {
        width: 32px;
        height: 32px;
        display: flex;
        align-items: center;
        justify-content: center;
        border-radius: 6px;
        font-weight: bold;
        font-size: 14px;
        transition: all 0.3s ease;
    }
    /* çŠ¶æ€ï¼šç­‰å¾…ä¸­ (ç°è‰²æè¾¹) */
    .chunk-pending {
        background-color: #ffffff;
        border: 2px solid #dee2e6;
        color: #adb5bd;
    }
    /* çŠ¶æ€ï¼šå¤„ç†ä¸­ (è“è‰²å‘¼å¸) */
    .chunk-active {
        background-color: #e7f1ff;
        border: 2px solid #0d6efd;
        color: #0d6efd;
        box-shadow: 0 0 8px rgba(13, 110, 253, 0.3);
    }
    /* çŠ¶æ€ï¼šå·²å®Œæˆ (ç»¿è‰²å¡«å……) */
    .chunk-done {
        background-color: #198754;
        border: 2px solid #198754;
        color: #ffffff;
    }

    /* æŒ‰é’® (ç»¿è‰²) */
    button[kind="primary"] {background-color: #198754 !important; border-color: #198754 !important; color: #FFFFFF !important;}
    
    .block-container {padding-top: 2rem !important;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•°åº“
# ==========================================

def render_chunk_visualizer(total, current_processing_index, container):
    """
    æ¸²æŸ“å¯è§†åŒ–çš„è¿›åº¦å—
    """
    html_content = '<div class="chunk-container">'
    for i in range(total):
        display_num = i + 1
        if i < current_processing_index:
            state_class = "chunk-done" # å·²å®Œæˆ
        elif i == current_processing_index:
            state_class = "chunk-active" # æ­£åœ¨å¤„ç†
        else:
            state_class = "chunk-pending" # ç­‰å¾…ä¸­
            
        html_content += f'<div class="chunk-box {state_class}">{display_num}</div>'
    html_content += '</div>'
    container.markdown(html_content, unsafe_allow_html=True)

def extract_url(text):
    pattern = r'(https?://\S+)'
    match = re.search(pattern, text)
    if match: return match.group(1)
    return None

def get_device_status():
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        return "cuda", f"âœ… GPU ({gpu_name})"
    else:
        return "cpu", "âš ï¸ CPU (Slow)"

@st.cache_resource
def load_whisper_model(model_size="base"):
    device, _ = get_device_status()
    try:
        return whisper.load_model(model_size, device=device)
    except:
        return whisper.load_model(model_size, device="cpu")

def smart_split_text(text, max_chars=1200):
    if not text: return []
    paragraphs = text.split('\n')
    chunks = []
    current_chunk = ""
    for p in paragraphs:
        if len(current_chunk) + len(p) < max_chars:
            current_chunk += p + "\n"
        else:
            if current_chunk:
                chunks.append(current_chunk)
                current_chunk = ""
            if len(p) > max_chars:
                for i in range(0, len(p), max_chars):
                    chunks.append(p[i:i+max_chars])
            else:
                current_chunk = p + "\n"
    if current_chunk: chunks.append(current_chunk)
    return chunks

def download_video_logic(url, mode="video"):
    download_dir = "downloads"
    if not os.path.exists(download_dir): os.makedirs(download_dir)
    ydl_opts = {
        'outtmpl': f'{download_dir}/%(title)s.%(ext)s',
        'quiet': True, 'no_warnings': True, 'restrictfilenames': False, 'updatetime': False,
        'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'
    }
    if mode == "audio":
        ydl_opts.update({'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio','preferredcodec': 'mp3','preferredquality': '192'}]})
    else:
        ydl_opts.update({'format': 'bestvideo+bestaudio/best'})
    
    if os.path.exists('cookies.txt'): ydl_opts['cookiefile'] = 'cookies.txt'

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
            valid_extensions = ['*.mp4', '*.mkv', '*.webm', '*.mp3', '*.m4a', '*.wav']
            list_of_files = []
            for ext in valid_extensions: list_of_files.extend(glob.glob(f'{download_dir}/{ext}'))
            if not list_of_files: return {"status": "error", "msg": "ä¸‹è½½æœªæ‰¾åˆ°æ–‡ä»¶"}
            latest_file = max(list_of_files, key=os.path.getmtime)
            return {"status": "success", "file_path": latest_file, "title": os.path.basename(latest_file), "thumbnail": None}
    except Exception as e: return {"status": "error", "msg": str(e)}

def transcribe_logic(file_path, model_size="base"):
    model = load_whisper_model(model_size)
    prompt = "ä»¥ä¸‹æ˜¯ç®€ä½“ä¸­æ–‡çš„å¯¹è¯å†…å®¹ï¼ŒåŒ…å«æ ‡ç‚¹ç¬¦å·ï¼Œé€»è¾‘æ¸…æ™°ã€‚"
    result = model.transcribe(file_path, language="zh", initial_prompt=prompt)
    return zhconv.convert(result["text"], 'zh-cn')

# ==========================================
# 4. ä¾§è¾¹æ é…ç½®
# ==========================================
with st.sidebar:
    st.markdown("## ğŸŒŠ DeepFlow v8.3")
    st.caption("Visual Chunking Edition")
    st.markdown("---")
    
    _, device_msg = get_device_status()
    if "GPU" in device_msg: st.success(device_msg)
    else: st.warning(device_msg)
    st.markdown("---")
    
    app_mode = st.radio("Navigation", ["ğŸ“ æ–‡æœ¬æ™ºèƒ½æ¶¦è‰²", "ğŸ¬ è§†é¢‘ä¸‹è½½ä¸è½¬å½•"], index=0)
    st.markdown("---")

    if app_mode == "ğŸ“ æ–‡æœ¬æ™ºèƒ½æ¶¦è‰²":
        st.markdown("#### ğŸ”‘ APIè®¾ç½®")
        api_key = st.text_input("API Key", type="password")
        base_url = st.text_input("Base URL", value="https://api.deepseek.com")
        model_name = st.selectbox("Model", ["deepseek-chat", "deepseek-coder"], index=0)
        
        st.markdown("---")
        st.markdown("#### ğŸ› ï¸ ä»»åŠ¡é¢„è®¾")
        
        PROMPT_MAP = {
            "å½•éŸ³ç¨¿æ·±åº¦æ•´ç† (Deep Clean)": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡å­—ç¼–è¾‘ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·è¾“å…¥çš„ã€å£è¯­å½•éŸ³æ–‡æœ¬ã€‘è½¬å†™æˆå»é™¤å£è¯­åŒ–çš„æ–‡æœ¬ã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. **å»å£è¯­åŒ–**ï¼šæ¶ˆé™¤å½•éŸ³æ–‡å­—ä¸­çš„åœé¡¿ã€é‡å¤å’Œå£è¯­åŒ–è¯­æ°”è¯ã€‚
2. **ä»…ä»…æ ¡å‡†**ï¼šä»…æ ¡å‡†ï¼Œä¸æ”¹å†™ä»»ä½•åŸæ–‡ï¼Œç¡®ä¿æ–‡å­—å†…å®¹å¿ å®äºåŸæ–‡æœ¬ã€‚
3. **ä¿æŒåŸæ„**ï¼šä¸¥æ ¼ä¿æŒåŸæ–‡åŸæ„ã€‚
4. **ç¦æ­¢é—²èŠ**ï¼šç›´æ¥è¾“å‡ºç»“æœï¼Œä¸è¦è§£é‡Šï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¼€ã€‚
5. **åˆç†åˆ†æ®µ**ï¼šåˆç†åˆ†æ®µï¼Œé¿å…å•æ®µè¿‡é•¿ã€‚
6. **ç¿»è¯‘åŠŸèƒ½**ï¼šå¦‚æœç›‘æµ‹åˆ°ä¸»è¦å†…å®¹ä¸ºä¸­æ–‡ä»¥å¤–çš„å†…å®¹ï¼ŒåŒæ ·ä»¥ä¿ç•™åŸæ–‡åŸæ„çš„æ–¹å¼ç¿»è¯‘ä¸ºä¸­æ–‡ã€‚""",
            
            "é€šç”¨åŠ©æ‰‹ (General)": """ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†æ¸Šåšã€é€»è¾‘ä¸¥å¯†çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

è¯·éµå¾ªä»¥ä¸‹å›ç­”åŸåˆ™ï¼š
1. **å‡†ç¡®æ€§ä¼˜å…ˆ**ï¼šç¡®ä¿æä¾›çš„ä¿¡æ¯å‡†ç¡®æ— è¯¯ã€‚
2. **é€»è¾‘æ¸…æ™°**ï¼šå›ç­”å¤æ‚é—®é¢˜æ—¶ï¼Œè¯·åˆ†æ­¥éª¤ã€åˆ†ç‚¹è¿›è¡Œé˜è¿°ã€‚
3. **æ ¼å¼è§„èŒƒ**ï¼šé€‚å½“ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¦‚åŠ ç²—ã€åˆ—è¡¨ï¼‰ã€‚""",
            
            "æ–‡æœ¬æ¶¦è‰² (Polishing)": """ä½ æ˜¯ä¸€ä½èµ„æ·±å‡ºç‰ˆç¼–è¾‘ã€‚è¯·å¯¹ç”¨æˆ·æä¾›çš„æ–‡æœ¬è¿›è¡Œæ·±åº¦æ¶¦è‰²ã€‚

ç›®æ ‡ï¼šè®©æ–‡ç« è¯»èµ·æ¥æ›´ä¸“ä¸šã€æ›´æµç•…ã€æ›´æœ‰æ–‡é‡‡ã€‚

æ“ä½œï¼š
1. **ä¿®æ­£è¯­ç—…**ï¼šä¿®å¤æ‰€æœ‰è¯­æ³•é”™è¯¯ã€‚
2. **æå‡è¯æ±‡**ï¼šæ›¿æ¢å£è¯­åŒ–è¯æ±‡ã€‚
3. **ä¼˜åŒ–å¥å¼**ï¼šå¢å¼ºè¯­è¨€èŠ‚å¥æ„Ÿã€‚""",
            
            "ä»£ç è§£é‡Š (Code Expert)": """ä½ æ˜¯ä¸€ä½èµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚è¯·åˆ†æä»£ç ã€‚

è¾“å‡ºç»“æ„ï¼š
1. **åŠŸèƒ½è§£è¯»**ï¼šè§£é‡Šä»£ç åœ¨åšä»€ä¹ˆã€‚
2. **ä»£ç ä¼˜åŒ–**ï¼šæŒ‡å‡ºé—®é¢˜å¹¶æä¾›ä¼˜åŒ–åçš„ä»£ç ã€‚
3. **å…³é”®æ³¨é‡Š**ï¼šæ·»åŠ è¯¦ç»†ä¸­æ–‡æ³¨é‡Šã€‚""",
            
            "ä¼šè®®çºªè¦æ€»ç»“ (Summarization)": """ä½ æ˜¯ä¸€ä½é«˜æ•ˆçš„è¡Œæ”¿ç§˜ä¹¦ã€‚è¯·å°†æ–‡æœ¬æ•´ç†ä¸ºä¼šè®®çºªè¦ã€‚

è¾“å‡ºæ ¼å¼ï¼š
1. **ğŸ“œ æ ¸å¿ƒè®®é¢˜**
2. **ğŸ—£ï¸ è¯¦ç»†æ‘˜è¦** (Bullet points)
3. **âœ… å¾…åŠäº‹é¡¹**
4. **ğŸ“Œ ç»“è®º/å†³ç­–**"""
        }

        TEMP_MAP = {
            "å½•éŸ³ç¨¿æ·±åº¦æ•´ç† (Deep Clean)": 0.1,
            "é€šç”¨åŠ©æ‰‹ (General)": 1.0,
            "æ–‡æœ¬æ¶¦è‰² (Polishing)": 1.0,
            "ä»£ç è§£é‡Š (Code Expert)": 0.2,
            "ä¼šè®®çºªè¦æ€»ç»“ (Summarization)": 0.5
        }

        if "user_system_prompt" not in st.session_state:
            st.session_state.user_system_prompt = PROMPT_MAP["å½•éŸ³ç¨¿æ·±åº¦æ•´ç† (Deep Clean)"]
        if "user_temperature" not in st.session_state:
            st.session_state.user_temperature = TEMP_MAP["å½•éŸ³ç¨¿æ·±åº¦æ•´ç† (Deep Clean)"]

        def on_preset_change():
            selected = st.session_state.preset_selector
            st.session_state.user_system_prompt = PROMPT_MAP[selected]
            st.session_state.user_temperature = TEMP_MAP[selected]

        st.selectbox("é€‰æ‹©é¢„è®¾", list(PROMPT_MAP.keys()), key="preset_selector", on_change=on_preset_change)
        temperature = st.slider("åˆ›æ„æ¸©åº¦", 0.0, 1.5, key="user_temperature", step=0.1)
        
        st.markdown("---")
        st.markdown("#### ğŸ“ é•¿æ–‡ä¼˜åŒ–")
        enable_chunking = st.checkbox("å¯ç”¨åˆ†æ®µå¤„ç† (Chunking)", value=True)
        chunk_size = st.number_input("åˆ†æ®µå­—ç¬¦æ•°", min_value=500, max_value=4000, value=1500, step=100)

    elif app_mode == "ğŸ¬ è§†é¢‘ä¸‹è½½ä¸è½¬å½•":
        st.markdown("#### âš™ï¸ Whisper è®¾ç½®")
        whisper_model = st.selectbox("æ¨¡å‹å¤§å°", ["tiny", "base", "small", "medium", "large"], index=1)
        st.markdown("#### ğŸ“¥ ä¸‹è½½è®¾ç½®")
        download_format = st.radio("æ–‡ä»¶æ ¼å¼", ["è§†é¢‘ (MP4)", "çº¯éŸ³é¢‘ (MP3)"], index=0)

# ==========================================
# 5. ä¸»ç•Œé¢é€»è¾‘
# ==========================================
if app_mode == "ğŸ“ æ–‡æœ¬æ™ºèƒ½æ¶¦è‰²":
    # ã€ä¿®å¤é‡ç‚¹ã€‘ä½¿ç”¨ HTML ç›´æ¥æ¸²æŸ“æ ‡é¢˜ï¼Œå¼ºåˆ¶è®¾ç½®å¯¹é½å’Œè¾¹è·ï¼Œé˜²æ­¢ Emoji è¢«åˆ‡æ–­
    st.markdown("""
        <div style="display: flex; align-items: center; gap: 8px; margin-bottom: 5px;">
            <span style="font-size: 1.4rem;">ğŸ§ </span>
            <h4 style="margin: 0; padding: 0;">ç³»ç»ŸæŒ‡ä»¤æ§åˆ¶ (System Prompt)</h4>
        </div>
    """, unsafe_allow_html=True)
    
    system_prompt_input = st.text_area("System Prompt", height=100, key="user_system_prompt", label_visibility="collapsed")
    
    st.markdown("---")
    col_in, col_out = st.columns([1, 1])
    with col_in:
        user_input_temp = st.session_state.get("user_input_temp", "")
        count_str = f"{len(user_input_temp)} å­—" if user_input_temp else "0 å­—"
        
        # åŒæ ·ä¼˜åŒ–"åŸå§‹æ–‡æœ¬"çš„æ ‡é¢˜æ˜¾ç¤º
        st.markdown(f"""
            <div style="display: flex; align-items: center; justify-content: space-between; margin-bottom: 5px;">
                <h4 style="margin: 0;">ğŸ“„ åŸå§‹æ–‡æœ¬</h4>
                <span style='font-size:0.9em;color:#6c757d; font-family: monospace;'>{count_str}</span>
            </div>
        """, unsafe_allow_html=True)
        
        user_input = st.text_area("Input", height=500, label_visibility="collapsed", placeholder="è¾“å…¥æ–‡æœ¬...", key="user_input_temp")
        
        if "last_transcription" in st.session_state and st.session_state.last_transcription:
            if st.button("ğŸ“¥ å¡«å…¥åˆšåˆšè½¬å½•çš„æ–‡æœ¬"):
                st.info("è¯·å¤åˆ¶ä¸‹æ–¹ä»£ç å—å†…å®¹åˆ°è¾“å…¥æ¡† (Streamlit å®‰å…¨é™åˆ¶æ— æ³•ç›´æ¥å†™å…¥)") 
                st.code(st.session_state.last_transcription, language=None)
        
        start_btn = st.button("ğŸš€ å¯åŠ¨å¤„ç†ä»»åŠ¡", type="primary", use_container_width=True)
        
    with col_out:
        st.markdown("#### ğŸ¤– DeepSeek å“åº”")
        
        result_container = st.container(border=True, height=500)
        
        if start_btn:
            if not api_key: st.error("è¯·é…ç½® API Key")
            elif not user_input: st.warning("è¯·è¾“å…¥å†…å®¹")
            else:
                client = OpenAI(api_key=api_key, base_url=base_url)
                
                if not enable_chunking or len(user_input) < chunk_size:
                    with st.spinner("æ€è€ƒä¸­..."):
                        with result_container:
                            try:
                                stream = client.chat.completions.create(
                                    model=model_name,
                                    messages=[{"role":"system","content":system_prompt_input},{"role":"user","content":user_input}],
                                    temperature=temperature, stream=True
                                )
                                st.write_stream(stream)
                            except Exception as e: st.error(f"Error: {e}")
                            
                else:
                    chunks = smart_split_text(user_input, max_chars=chunk_size)
                    total_chunks = len(chunks)
                    full_response_text = ""
                    
                    with result_container:
                        vis_placeholder = st.empty()
                        
                        render_chunk_visualizer(total_chunks, -1, vis_placeholder)
                        
                        for idx, chunk in enumerate(chunks):
                            render_chunk_visualizer(total_chunks, idx, vis_placeholder)
                            
                            st.caption(f"ğŸ“ æ­£åœ¨å¤„ç†: Part {idx+1} / {total_chunks}")
                            
                            try:
                                stream = client.chat.completions.create(
                                    model=model_name,
                                    messages=[{"role":"system","content":system_prompt_input},{"role":"user","content":chunk}],
                                    temperature=temperature, stream=True
                                )
                                chunk_resp = st.write_stream(stream)
                                full_response_text += chunk_resp + "\n\n"
                                st.markdown("---")
                                
                            except Exception as e:
                                st.error(f"Error in chunk {idx+1}: {e}")
                                break
                        
                        render_chunk_visualizer(total_chunks, total_chunks, vis_placeholder)
                    
                    with st.expander("ğŸ“¥ è·å–å®Œæ•´åˆå¹¶æ–‡æœ¬", expanded=True):
                        st.text_area("Full Result", value=full_response_text, height=200)
                        st.success(f"âœ… å¤„ç†å®Œæˆï¼å…± {len(full_response_text)} å­—")

elif app_mode == "ğŸ¬ è§†é¢‘ä¸‹è½½ä¸è½¬å½•":
    st.markdown("#### ğŸ”— è§†é¢‘é“¾æ¥è§£æ")
    url_input = st.text_area("Input URL", height=100, placeholder="åœ¨æ­¤ç²˜è´´ Bç«™/æŠ–éŸ³/Youtube é“¾æ¥...", label_visibility="collapsed")
    col_dl_1, col_dl_2 = st.columns([1, 4])
    
    dl_btn_label = "â¬‡ï¸ ä¸‹è½½è§†é¢‘" if "è§†é¢‘" in download_format else "â¬‡ï¸ ä¸‹è½½éŸ³é¢‘ (MP3)"
    with col_dl_1: analyze_btn = st.button(dl_btn_label, type="primary", use_container_width=True)
    st.markdown("---")
    
    if "current_video_path" not in st.session_state: st.session_state.current_video_path = None
    
    if analyze_btn and url_input:
        real_url = extract_url(url_input)
        if not real_url: st.error("âŒ æœªèƒ½åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„ http é“¾æ¥")
        else:
            mode_code = "audio" if "MP3" in download_format else "video"
            with st.status(f"æ­£åœ¨ä¸‹è½½{'éŸ³é¢‘' if mode_code == 'audio' else 'è§†é¢‘'}...", expanded=True) as status:
                st.write(f"ğŸ”— è§£æé“¾æ¥: `{real_url}`")
                result = download_video_logic(real_url, mode=mode_code)
                if result["status"] == "success":
                    status.update(label="âœ… ä¸‹è½½æˆåŠŸï¼", state="complete", expanded=False)
                    st.session_state.current_video_path = result["file_path"]
                    st.session_state.current_video_title = result["title"]
                    st.rerun()
                else:
                    status.update(label="âŒ ä¸‹è½½å¤±è´¥", state="error")
                    st.error(result["msg"])

    if st.session_state.current_video_path and os.path.exists(st.session_state.current_video_path):
        st.success(f"ğŸ“‚ æ–‡ä»¶å·²å°±ç»ª: `{st.session_state.current_video_path}`")
        col_v_1, col_v_2 = st.columns([1, 1])
        with col_v_1:
            st.markdown("#### ğŸ“º æ–‡ä»¶é¢„è§ˆ")
            if st.session_state.current_video_path.endswith(".mp4"):
                st.video(st.session_state.current_video_path)
            else:
                st.audio(st.session_state.current_video_path)
                
        with col_v_2:
            st.markdown("#### ğŸ“ è¯­éŸ³è½¬å½• (Whisper)")
            transcribe_btn = st.button("ğŸ™ï¸ å¼€å§‹è½¬å½•ä¸ºæ–‡å­—", type="primary", use_container_width=True)
            
            if transcribe_btn:
                with st.status("Whisper æ¨¡å‹æ­£åœ¨è¿è¡Œä¸­...", expanded=True) as t_status:
                    try:
                        text_result = transcribe_logic(st.session_state.current_video_path, whisper_model)
                        t_status.update(label="âœ… è½¬å½•å®Œæˆï¼", state="complete", expanded=False)
                        st.text_area("è½¬å½•ç»“æœ", value=text_result, height=300)
                        st.session_state.last_transcription = text_result
                        st.info("ğŸ’¡ æç¤ºï¼šè½¬å½•å†…å®¹å·²ä¿å­˜ã€‚")
                    except Exception as e:
                        t_status.update(label="âŒ è½¬å½•å¤±è´¥", state="error")
                        st.error(f"Whisper é”™è¯¯: {str(e)}")